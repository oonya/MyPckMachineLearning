{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UseI2v.ipynb",
      "provenance": [],
      "mount_file_id": "1nwILL0kwGB21mZBzQAGLgCZjw9UsHX_Z",
      "authorship_tag": "ABX9TyPp8dEG8N3fzP2q98DeJ1yX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oonya/MyPckMachineLearning/blob/main/UseI2v.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWTw2w6Ey9oi",
        "outputId": "663adad7-6e3a-4582-d861-e83a406b7a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        }
      },
      "source": [
        "!pip install illustration2vec"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting illustration2vec\n",
            "  Downloading https://files.pythonhosted.org/packages/5f/de/681f6ba85284ad605a93a2265fd6803b487d7d324dd35883bf57de0a3253/illustration2vec-0.1.0.tar.gz\n",
            "Requirement already satisfied: chainer>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from illustration2vec) (7.4.0)\n",
            "Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.6/dist-packages (from illustration2vec) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from illustration2vec) (1.18.5)\n",
            "Requirement already satisfied: Pillow>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from illustration2vec) (7.0.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from illustration2vec) (0.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer>=4.1.0->illustration2vec) (3.0.12)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer>=4.1.0->illustration2vec) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer>=4.1.0->illustration2vec) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from chainer>=4.1.0->illustration2vec) (50.3.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from chainer>=4.1.0->illustration2vec) (3.7.4.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.0->illustration2vec) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.0->illustration2vec) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.0->illustration2vec) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.0->illustration2vec) (2.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.0->illustration2vec) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.0->illustration2vec) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.0->illustration2vec) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.0->illustration2vec) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.0->illustration2vec) (2.8.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.0->illustration2vec) (4.4.2)\n",
            "Building wheels for collected packages: illustration2vec\n",
            "  Building wheel for illustration2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for illustration2vec: filename=illustration2vec-0.1.0-cp36-none-any.whl size=9645 sha256=4b51f115ad91404255a05aae065cd6e65fc8cb66d0aed2b781a6e44ea5314c87\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ab/0d/3f40e0e6ed336a058cd7a3fb897a998ca85274039d5167d1e5\n",
            "Successfully built illustration2vec\n",
            "Installing collected packages: illustration2vec\n",
            "Successfully installed illustration2vec-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LebEUhdRFjSo"
      },
      "source": [
        "import i2v\n",
        "from PIL import Image\n",
        "\n",
        "path = 'drive/My Drive/illustration2vec/'\n",
        "\n",
        "# In the feature vector extraction, you do not need to specify the tag.\n",
        "illust2vec = i2v.make_i2v_with_chainer(path+\"illust2vec_ver200.caffemodel\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gphRbbyRwyLc",
        "outputId": "3a968806-7623-41b2-d47d-fa66619181af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "img = Image.open(path+\"images/miku.jpg\")\n",
        "\n",
        "# extract a 4,096-dimensional feature vector\n",
        "result_real = illust2vec.extract_feature([img])\n",
        "print(\"shape: {}, dtype: {}\".format(result_real.shape, result_real.dtype))\n",
        "print(result_real)\n",
        "\n",
        "\n",
        "type([np.uint8([[1, 2, 3]]), 0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape: (1, 4096), dtype: float32\n",
            "[[7.6607313 4.6432104 0.8488899 ... 0.3083177 1.641011  7.47949  ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVZdNl12o82J"
      },
      "source": [
        "# 今はdriveから読み込んでいるので必要ない\n",
        "\n",
        "%%bash\n",
        "\n",
        "# git clone https://github.com/rezoo/illustration2vec.git\n",
        "# sh illustration2vec/get_models.sh\n",
        "# pip install illustration2vec\n",
        "\n",
        "\n",
        "# mv illustration2vec/ drive/My\\ Drive\n",
        "# ls drive/My\\ Drive/illustration2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMFWeFk15AgE",
        "outputId": "401ed3a2-1367-4bc9-94b6-43afee8bec72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# データセットを作る\n",
        "# iv2でmodelを読み込み済み(重いからセルを分けただけ)\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "trainpath = 'drive/My Drive/picturesForMachineLearning/train/'\n",
        "animal_path = 'animal_img/'\n",
        "person_path = 'person_img/'\n",
        "\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "\n",
        "train_data = []\n",
        "for filename in os.listdir(trainpath + person_path):\n",
        "  img = Image.open(trainpath + person_path + filename)\n",
        "  result_real = illust2vec.extract_feature([img])\n",
        "\n",
        "  train_data.append([result_real, 0])\n",
        "\n",
        "  cnt += 1\n",
        "  # if cnt > 5:\n",
        "  #   break\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "for filename in os.listdir(trainpath + animal_path):\n",
        "  try:\n",
        "    img = Image.open(trainpath + animal_path + filename)\n",
        "    result_real = illust2vec.extract_feature([img])\n",
        "\n",
        "    train_data.append([result_real, 1])\n",
        "  except Exception as e:\n",
        "    print(e, filename)\n",
        "    pass\n",
        "\n",
        "  cnt += 1\n",
        "  # if cnt > 5:\n",
        "  #   break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# [np.uint8([[1, 2, 3]]), 0]\n",
        "\n",
        "# train_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "operands could not be broadcast together with shapes (3,) (2,)  g.png\n",
            "operands could not be broadcast together with shapes (3,) (2,)  e12.png\n",
            "operands could not be broadcast together with shapes (3,) (2,)  e (4).png\n",
            "operands could not be broadcast together with shapes (3,) (2,)  shirokuma-shirokuro-400x400.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqSV2MlgMpAf",
        "outputId": "b2b2d3a7-d827-4b93-b9a9-d31bb1c7a08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# test用のデータ\n",
        "# 名前はvalidになってるけど、それはごめん\n",
        "# iv2でmodelを読み込み済み(重いからセルを分けただけ)\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "validpath = 'drive/My Drive/picturesForMachineLearning/valid/'\n",
        "animal_path = 'animal_img/'\n",
        "person_path = 'person_img/'\n",
        "\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "\n",
        "train_data = []\n",
        "for filename in os.listdir(validpath + person_path):\n",
        "  img = Image.open(validpath + person_path + filename)\n",
        "  result_real = illust2vec.extract_feature([img])\n",
        "\n",
        "  train_data.append([result_real, 0])\n",
        "\n",
        "  cnt += 1\n",
        "  # if cnt > 5:\n",
        "  #   break\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "for filename in os.listdir(validpath + animal_path):\n",
        "  try:\n",
        "    img = Image.open(validpath + animal_path + filename)\n",
        "    result_real = illust2vec.extract_feature([img])\n",
        "\n",
        "    train_data.append([result_real, 1])\n",
        "  except Exception as e:\n",
        "    print(e, filename)\n",
        "    pass\n",
        "\n",
        "  cnt += 1\n",
        "  # if cnt > 5:\n",
        "  #   break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train_data"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "operands could not be broadcast together with shapes (3,) (2,)  18.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKxhls0yNunQ",
        "outputId": "b0138fd5-0a94-4224-d485-bafc28ee3ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# to make dataset takes 2 minutes\n",
        "\n",
        "import numpy as np\n",
        "rng = np.random.default_rng()\n",
        "r_a = rng.permutation(train_data)\n",
        "\n",
        "valid_vector = r_a[:, 0]\n",
        "valid_vector = np.concatenate(valid_vector)\n",
        "valid_label = r_a[:, 1]\n",
        "valid_label=np.array(valid_label,dtype='float32')\n",
        "\n",
        "print(valid_vector.shape)\n",
        "print(valid_label.shape)\n",
        "\n",
        "np.save('drive/My Drive/pck_machineLearning/valid_vector', valid_vector)\n",
        "np.save('drive/My Drive/pck_machineLearning/valid_label', valid_label)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59, 4096)\n",
            "(59,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVVy2voULgFp",
        "outputId": "d201d42e-af57-4143-c47e-77ba4a05bb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# to make dataset takes 2 minutes\n",
        "\n",
        "import numpy as np\n",
        "rng = np.random.default_rng()\n",
        "r_a = rng.permutation(train_data)\n",
        "\n",
        "vector = r_a[:, 0]\n",
        "vector = np.concatenate(vector)\n",
        "label = r_a[:, 1]\n",
        "label=np.array(label,dtype='float32')\n",
        "\n",
        "\n",
        "a = np.array([0, 1], np.float32)\n",
        "# print(a)\n",
        "# print(vector.shape)\n",
        "\n",
        "print(vector.shape)\n",
        "print(label.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(236, 4096)\n",
            "(236,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-FG2icqOCxe"
      },
      "source": [
        "np.save('drive/My Drive/pck_machineLearning/vecotrArray', vector)\n",
        "np.save('drive/My Drive/pck_machineLearning/labelArray', label)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM5EKni_w2wp",
        "outputId": "c40b11e7-4a58-45fd-f917-f36b4e0df27f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Activation\n",
        "import tensorflow.keras\n",
        "\n",
        "N_CATEGORIES = 1\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=32, activation='relu',input_shape=(4096,)))\n",
        "model.add(Dense(units=N_CATEGORIES, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "# print(model.summary())\n",
        "model.fit(vector, label, epochs=30, batch_size=32,validation_split=0.1)\n",
        "\n",
        "\n",
        "path = 'drive/My Drive/pck_machineLearning'\n",
        "model.save(filepath='drive/My Drive/pck_machineLearning/pck_model_activationSigmoid.h5', save_format='h5')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.8321 - accuracy: 0.7689 - val_loss: 0.2954 - val_accuracy: 0.8750\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2404 - accuracy: 0.9104 - val_loss: 0.2572 - val_accuracy: 0.9167\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1847 - accuracy: 0.9245 - val_loss: 0.0690 - val_accuracy: 0.9583\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1320 - accuracy: 0.9387 - val_loss: 0.0468 - val_accuracy: 0.9583\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9623 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9623 - val_loss: 0.0603 - val_accuracy: 0.9583\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9670 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9811 - val_loss: 0.0565 - val_accuracy: 0.9583\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9623 - val_loss: 0.0349 - val_accuracy: 0.9583\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9717 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9906 - val_loss: 0.0370 - val_accuracy: 0.9583\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9906 - val_loss: 0.0504 - val_accuracy: 0.9583\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9953 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9858 - val_loss: 0.0364 - val_accuracy: 0.9583\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9906 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9953 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.9953 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9953 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REJaDsIhMaDV",
        "outputId": "c0f58fde-41a4-44e1-8355-01ecc5d27144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "score = model.evaluate(valid_vector, valid_label, verbose=1)\n",
        "print('正解率=', score[1], 'loss=', score[0])\t"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9492\n",
            "正解率= 0.9491525292396545 loss= 0.2106798142194748\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}