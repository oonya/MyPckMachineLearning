{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i2v_2Keras.ipynb",
      "provenance": [],
      "mount_file_id": "1Ke0n15aCJboYCv7rojCVfA3G_QyXN_gF",
      "authorship_tag": "ABX9TyNNFvXYL8my7LjLqq1YzmJc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oonya/MyPckMachineLearning/blob/main/i2v_2Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMGM2vJt3LGP",
        "outputId": "e07948f3-d64b-4396-eb06-ab8910693f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash\n",
        "# 動かす時は以下のコマンドで訓練済みモデルをダウンロードしてくる(自分のコードはdriveに.caffemodelなどが保存してある)\n",
        "# git clone https://github.com/rezoo/illustration2vec.git\n",
        "# sh illustration2vec/get_models.sh\n",
        "\n",
        "\n",
        "# apt install caffe-cpu\n",
        "# pip install mmdnn\n",
        "\n",
        "# cd illustration2vec/\n",
        "# mmconvert --srcFramework caffe --inputWeight illust2vec_ver200.caffemodel --inputNetwork illust2vec_tag.prototxt --dstFramework keras --outputModel reserve.hdf5\n",
        "# mmconvert --srcFramework caffe --inputWeight illust2vec_ver200.caffemodel --inputNetwork illust2vec_tag.prototxt --dstFramework keras --outputModel inshape50_224224_3VER200.hdf5 --inputShape 50,224,224,3\n",
        "# mmconvert --srcFramework caffe --inputWeight illust2vec_ver200.caffemodel --inputNetwork illust2vec_tag.prototxt --dstFramework keras --outputModel inshape50_3_224224VER200.hdf5 --inputShape 50,3,224,244\n",
        "\n",
        "ls illustration2vec/reserve.hdf5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "get_models.sh\n",
            "i2v\n",
            "illust2vec_tag.prototxt\n",
            "illust2vec_tag_ver200.caffemodel\n",
            "illust2vec_ver200.caffemodel\n",
            "images\n",
            "LICENSE\n",
            "papers\n",
            "__pycache__\n",
            "README.md\n",
            "requirements.txt\n",
            "reserve.hdf5\n",
            "tag_list.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQEjq-QnJj7C"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "import keras.callbacks\n",
        "import tensorflow as tf\n",
        "import os.path\n",
        "\n",
        "\n",
        "from keras.models import load_model\n",
        "model = load_model('drive/My Drive/saveFolderForMachineLearning/inshape50_224224_3VER200.hdf5', compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cScnB4mJmp8",
        "outputId": "642a6d61-0a82-4f35-9d18-914d37ed8626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\n",
        "\n",
        "img_pil = tf.keras.preprocessing.image.load_img(\n",
        "  'drive/My Drive/miku.jpg', target_size=(224, 224)\n",
        ")\n",
        "img = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
        "\n",
        "img = img[tf.newaxis, ...]\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "pre = model.predict(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrpsmyTjJoAM",
        "outputId": "05e46bd3-2ac9-4956-8ee4-94a9857ea601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(pre[0, 0, 0, :5])\n",
        "print(pre.shape)\n",
        "\n",
        "print(np.max(pre))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5 0.5 0.5 0.5 0.5]\n",
            "(1, 1, 1, 1539)\n",
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s3z5mXDTRUC",
        "outputId": "f5cfa505-1ee9-4468-9129-1b042e0bf815",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# inputShapeの違う方のhdf5\n",
        "\n",
        "from keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('drive/My Drive/saveFolderForMachineLearning/inshape50_224224_3VER200.hdf5', compile=False)\n",
        "\n",
        "img_pil = tf.keras.preprocessing.image.load_img(\n",
        "  'drive/My Drive/miku.jpg', target_size=(224, 224)\n",
        ")\n",
        "img = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
        "\n",
        "# shapeを変えずにpredictする\n",
        "img = img[tf.newaxis, ...]\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "pre = model.predict(img)\n",
        "\n",
        "print(pre[0, 0, 0, :5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 224, 224, 3)\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2da04ecc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[0.5 0.5 0.5 0.5 0.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_smQf39T375",
        "outputId": "ffdbac2a-d7e7-4d50-edf1-8dc20e8d3cba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# inputShapeの違う方のhdf5\n",
        "\n",
        "from keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('drive/My Drive/saveFolderForMachineLearning/inshape50_3_224224VER200.hdf5', compile=False)\n",
        "\n",
        "img_pil = tf.keras.preprocessing.image.load_img(\n",
        "  'drive/My Drive/miku.jpg', target_size=(224, 224)\n",
        ")\n",
        "img = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
        "\n",
        "# shapeを変ええてpredictする\n",
        "img = img.reshape((3, 224, 224))\n",
        "img = img[tf.newaxis, ...]\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "# pre = model.predict(img)\n",
        "\n",
        "# print(pre[0, 0, 0, :5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEVQEcjAW6q6",
        "outputId": "d990ece4-7a99-4098-85ba-a4f04266a170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = load_model('illustration2vec/reserve.hdf5', compile=False)\n",
        "# illustration2vec/reserve.hdf5\n",
        "model.inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'data_10:0' shape=(None, 224, 224, 3) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    }
  ]
}